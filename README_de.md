# üöÄ DataNova

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[English](./README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README_zh.md) | [Êó•Êú¨Ë™û](./README_ja.md) | [Deutsch](./README_de.md) | [Espa√±ol](./README_es.md) | [–†—É—Å—Å–∫–∏–π](./README_ru.md) |[Portuguese](./README_pt.md)

> Datenlagerentwicklung mit KI-Intelligenz revolutionieren

**DataNova** ist eine KI-gest√ºtzte Datenlagerentwicklungsplattform, die gro√üe Sprachmodelle mit spezialisierten Tools kombiniert, um Datenteams intelligente Datenarchitekturdesign-, Abfrageoptimierungs- und automatisierte Pipeline-Generierungsfunktionen zu bieten. Unser Ziel ist es, die traditionelle Datenlagerentwicklung durch KI-gesteuerte Erkenntnisse und Empfehlungen zu transformieren.

DataNova ist jetzt offiziell im [FaaS-Anwendungszentrum von Volcengine](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market) verf√ºgbar, wo Benutzer √ºber den [Erfahrungslink](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market/datanova/?channel=github&source=datanova) eine Online-Erfahrung machen und seine leistungsstarken Funktionen und bequemen Bedienung intuitiv sp√ºren k√∂nnen. Gleichzeitig unterst√ºtzt DataNova zur Erf√ºllung der Bereitstellungsanforderungen verschiedener Benutzer eine One-Click-Bereitstellung basierend auf Volcengine. Klicken Sie auf den [Bereitstellungslink](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/application/create?templateId=683adf9e372daa0008aaed5c&channel=github&source=datanova), um den Bereitstellungsprozess schnell abzuschlie√üen und Ihre intelligente Datenlagerentwicklungsreise zu beginnen.

Bitte besuchen Sie die [offizielle Website von DataNova](https://datanova.tech/) f√ºr weitere Details.

## Demo

### Video

<https://github.com/user-attachments/assets/f3786598-1f2a-4d07-919e-8b99dfa1de3e>

In dieser Demo zeigen wir, wie man DataNova verwendet:

- Nahtlose Integration mit MCP-Services
- Durchf√ºhrung von Tiefgang-Datenanalyseprozessen und Erstellung umfassender Berichte mit Diagrammen
- Erstellung von Podcast-Audio basierend auf generierten Analyseberichten

### Wiederholungsbeispiele

- [Design eines Sternschemas f√ºr ein E-Commerce-Datenlager](https://datanova.tech/chat?replay=ecommerce-star-schema-design)
- [Optimierung der Leistung komplexer SQL-Abfragen](https://datanova.tech/chat?replay=sql-query-optimization)
- [Aufbau von Echtzeit-Datenpipelines zur Verarbeitung von Streaming-Daten](https://datanova.tech/chat?replay=realtime-data-pipeline)
- [Implementierung von Datenqualit√§ts√ºberwachung und Warnsystemen](https://datanova.tech/chat?replay=data-quality-monitoring)
- [Besuchen Sie unsere offizielle Website, um weitere Wiederholungsbeispiele zu erkunden.](https://datanova.tech/#case-studies)

---

## üìë Inhaltsverzeichnis

- [üöÄ Schnellstart](#schnellstart)
- [üåü Funktionen](#funktionen)
- [üèóÔ∏è Architektur](#architektur)
- [üõ†Ô∏è Entwicklung](#entwicklung)
- [üó£Ô∏è Text-to-Speech-Integration](#text-to-speech-integration)
- [üìö Beispiele](#beispiele)
- [‚ùì FAQ](#faq)
- [üìú Lizenz](#lizenz)
- [üíñ Danksagungen](#danksagungen)
- [‚≠ê Sternverlauf](#sternverlauf)

## Schnellstart

DataNova ist in Python entwickelt und verf√ºgt √ºber eine in Node.js geschriebene Web-Benutzeroberfl√§che. Um einen reibungslosen Setup-Prozess zu gew√§hrleisten, empfehlen wir die Verwendung der folgenden Tools:

### Empfohlene Tools

- **[`uv`](https://docs.astral.sh/uv/getting-started/installation/):**
  Vereinfacht die Python-Umgebungs- und Abh√§ngigkeitsverwaltung. `uv` erstellt automatisch eine virtuelle Umgebung im Stammverzeichnis und installiert alle erforderlichen Pakete f√ºr Sie‚Äîkeine manuelle Installation von Python-Umgebungen erforderlich.

- **[`nvm`](https://github.com/nvm-sh/nvm):**
  Einfache Verwaltung mehrerer Node.js-Laufzeitversionen.

- **[`pnpm`](https://pnpm.io/installation):**
  Installation und Verwaltung von Abh√§ngigkeiten f√ºr Node.js-Projekte.

### Umgebungsanforderungen

Stellen Sie sicher, dass Ihr System die folgenden Mindestanforderungen erf√ºllt:

- **[Python](https://www.python.org/downloads/):** Version `3.12+`
- **[Node.js](https://nodejs.org/en/download/):** Version `22+`

### Installation

```bash
# Repository klonen
git clone https://github.com/hszhsz/DataNova
cd DataNova

# Abh√§ngigkeiten installieren, uv √ºbernimmt die Erstellung des Python-Interpreters und der virtuellen Umgebung sowie die Installation der erforderlichen Pakete
uv sync

# .env mit Ihren API-Schl√ºsseln konfigurieren
# Tavily: https://app.tavily.com/home
# Brave_SEARCH: https://brave.com/search/api/
# Volcengine TTS: Hinzuf√ºgen, wenn Sie TTS-Anmeldeinformationen haben
cp .env.example .env

# Siehe die Abschnitte "Unterst√ºtzte Suchmaschinen" und "Text-to-Speech-Integration" unten f√ºr alle verf√ºgbaren Optionen

# conf.yaml mit Ihren LLM-Modellen und API-Schl√ºsseln konfigurieren
# Siehe 'docs/configuration_guide.md' f√ºr weitere Details
cp conf.yaml.example conf.yaml

# marp f√ºr PPT-Generierung installieren
# https://github.com/marp-team/marp-cli?tab=readme-ov-file#use-package-manager
brew install marp-cli
```

Optional Web-UI-Abh√§ngigkeiten √ºber [pnpm](https://pnpm.io/installation) installieren:

```bash
cd DataNova/web
pnpm install
```

### Konfiguration

Siehe [Konfigurationsanleitung](docs/configuration_guide.md) f√ºr weitere Details.

> [!NOTE]
> Bitte lesen Sie den Leitfaden sorgf√§ltig durch, bevor Sie das Projekt starten, und aktualisieren Sie die Konfiguration entsprechend Ihren spezifischen Einstellungen und Anforderungen.

### Konsolen-UI

Die schnellste M√∂glichkeit, das Projekt auszuf√ºhren, ist die Verwendung der Konsolen-UI.

```bash
# Das Projekt in einer bash-√§hnlichen Shell ausf√ºhren
uv run main.py
```

### Web-UI

Dieses Projekt enth√§lt auch eine Web-Benutzeroberfl√§che, die ein dynamischeres und ansprechenderes interaktives Erlebnis bietet.
> [!NOTE]
> Sie m√ºssen zuerst die Web-UI-Abh√§ngigkeiten installieren.

```bash
# Gleichzeitiges Ausf√ºhren von Backend- und Frontend-Servern im Entwicklungsmodus
# Auf macOS/Linux
./bootstrap.sh -d

# Auf Windows
bootstrap.bat -d
```

√ñffnen Sie Ihren Browser und besuchen Sie [`http://localhost:3000`](http://localhost:3000), um die Web-Benutzeroberfl√§che zu erkunden.

Erforschen Sie weitere Details im [`web`](./web/)-Verzeichnis.

## Unterst√ºtzte Suchmaschinen

### √ñffentliche Suchmaschinen

DataNova unterst√ºtzt mehrere Suchmaschinen, die in der `.env`-Datei √ºber die `SEARCH_API`-Variable konfiguriert werden k√∂nnen:

- **Tavily** (Standard): Professionelle Such-API, speziell f√ºr KI-Anwendungen entwickelt
  - Erfordert das Setzen von `TAVILY_API_KEY` in der `.env`-Datei
  - Registrierungsadresse: <https://app.tavily.com/home>

- **DuckDuckGo**: Datenschutzorientierte Suchmaschine
  - Kein API-Schl√ºssel erforderlich

- **Brave Search**: Datenschutzorientierte Suchmaschine mit erweiterten Funktionen
  - Erfordert das Setzen von `BRAVE_SEARCH_API_KEY` in der `.env`-Datei
  - Registrierungsadresse: <https://brave.com/search/api/>

- **Arxiv**: Wissenschaftliche Papier-Suche f√ºr akademische Forschung
  - Kein API-Schl√ºssel erforderlich
  - Speziell f√ºr wissenschaftliche und akademische Papiere entwickelt

Um Ihre bevorzugte Suchmaschine zu konfigurieren, setzen Sie die `SEARCH_API`-Variable in der `.env`-Datei:

```bash
# W√§hlen Sie eine aus: tavily, duckduckgo, brave_search, arxiv
SEARCH_API=tavily
```

### Private Wissensdatenbank-Engines

DataNova unterst√ºtzt die Suche basierend auf privatem Dom√§nenwissen. Sie k√∂nnen Dokumente in mehrere private Wissensdatenbanken hochladen, die w√§hrend der Datenanalyse verwendet werden. Derzeit unterst√ºtzte private Wissensdatenbanken sind:

- **[RAGFlow](https://ragflow.io/docs/dev/)**: Open-Source-Wissensdatenbank-Engine basierend auf Retrieval-Augmented Generation
   ```
   # Siehe .env.example f√ºr die Konfiguration
   RAG_PROVIDER=ragflow
   RAGFLOW_API_URL="http://localhost:9388"
   RAGFLOW_API_KEY="ragflow-xxx"
   RAGFLOW_RETRIEVAL_SIZE=10
   ```

- **[VikingDB Wissensdatenbank](https://www.volcengine.com/docs/84313/1254457)**: Public-Cloud-Wissensdatenbank-Engine von Volcengine
   > Hinweis: Zuerst AK/SK von [Volcengine](https://www.volcengine.com/docs/84313/1254485) abrufen
   ```
   # Siehe .env.example f√ºr die Konfiguration
   RAG_PROVIDER=vikingdb_knowledge_base
   VIKINGDB_KNOWLEDGE_BASE_API_URL="api-knowledgebase.mlp.cn-beijing.volces.com"
   VIKINGDB_KNOWLEDGE_BASE_API_AK="volcengine-ak-xxx"
   VIKINGDB_KNOWLEDGE_BASE_API_SK="volcengine-sk-xxx"
   VIKINGDB_KNOWLEDGE_BASE_RETRIEVAL_SIZE=15
   ```

## Funktionen

### Kernfunktionen

- ü§ñ **KI-gest√ºtztes Datenarchitekturdesign**
  - Unterst√ºtzt die Integration der meisten Modelle durch [litellm](https://docs.litellm.ai/docs/providers)
  - Unterst√ºtzt Open-Source-Modelle wie Qwen
  - Kompatibel mit OpenAI-API-Schnittstelle
  - Mehrschichtige LLM-Systeme f√ºr Aufgaben unterschiedlicher Komplexit√§t

### Datenwerkzeuge und MCP-Integration

- üîç **Datenexploration und -abruf**
  - Datenquellensuche durch Tavily, Brave Search und andere
  - Datencrawling mit Jina
  - Fortschrittliche Dateninhalts-Extraktion
  - Unterst√ºtzt den Abruf spezifizierter privater Wissensdatenbanken

- üìÉ **RAG-Integration**
  - Unterst√ºtzt [RAGFlow](https://github.com/infiniflow/ragflow)-Wissensdatenbank
  - Unterst√ºtzt [VikingDB](https://www.volcengine.com/docs/84313/1254457) Volcengine-Wissensdatenbank

- üîó **MCP nahtlose Integration**
  - Erweitert Funktionen f√ºr Datenquellenzugriff, Datenqualit√§tspr√ºfungen, Abfrageoptimierung und mehr
  - F√∂rdert die Integration vielf√§ltiger Datenwerkzeuge und -methoden

### KI-gest√ºtzte Zusammenarbeit

- üß† **Human-in-the-Loop**
  - Unterst√ºtzt interaktive √Ñnderung von Datenarchitekturpl√§nen mit nat√ºrlicher Sprache
  - Unterst√ºtzt automatische Annahme von Architekturpl√§nen

- üìù **Datenbericht-Post-Editing**
  - Unterst√ºtzt Notion-√§hnliche Block-Bearbeitung
  - Erm√∂glicht KI-Optimierung, einschlie√ülich KI-unterst√ºtzter Feinabstimmung, Satzverk√ºrzung und -erweiterung
  - Unterst√ºtzt von [tiptap](https://tiptap.dev/)

### Inhaltserstellung

- üéôÔ∏è **Podcast- und Pr√§sentationserstellung**
  - KI-gest√ºtzte Podcast-Skriptgenerierung und Audio-Synthese
  - Automatische Erstellung einfacher PowerPoint-Pr√§sentationen
  - Anpassbare Vorlagen zur Erf√ºllung personalisierter Inhaltsbed√ºrfnisse

## Architektur

DataNova implementiert eine modulare Multi-Agenten-Systemarchitektur, die f√ºr automatisierte Datenlagerentwicklung und Datenanalyse konzipiert ist. Das System basiert auf LangGraph und implementiert einen flexiblen zustandsbasierten Workflow, bei dem Komponenten durch ein klar definiertes Nachrichten√ºbermittlungssystem kommunizieren.

![Architekturdiagramm](./assets/architecture.png)

> Live-Demo unter [datanova.tech](https://datanova.tech/#multi-agent-architecture) anzeigen

Das System verwendet einen optimierten Workflow, der aus den folgenden Komponenten besteht:

1. **Koordinator**: Der Einstiegspunkt, der den Workflow-Lebenszyklus verwaltet

   - Initiierung des Datenanalyseprozesses basierend auf Benutzereingaben
   - Delegierung von Aufgaben an den Planer zu geeigneten Zeitpunkten
   - Dient als Hauptschnittstelle zwischen Benutzer und System

2. **Planer**: Die strategische Komponente, die f√ºr Aufgabendekomposition und -planung verantwortlich ist

   - Analyse von Datenanalysezielen und Erstellung strukturierter Ausf√ºhrungspl√§ne
   - Bestimmung, ob ausreichend Kontext vorhanden ist oder mehr Datenexploration erforderlich ist
   - Verwaltung des Datenanalyseprozesses und Entscheidung, wann der Abschlussbericht generiert wird

3. **Datenanalyseteam**: Eine Sammlung spezialisierter Agenten, die den Plan ausf√ºhren:
   - **Datenanalyst**: Durchf√ºhrung von Datensuche und Informationssammlung mit Tools wie Datensuchmaschinen, Crawlern und sogar MCP-Services.
   - **Dateningenieur**: Handhabung von Datenverarbeitung, Analyse und technischen Aufgaben mit Python REPL-Tools.
   Jeder Agent hat Zugriff auf spezifische, f√ºr seine Rolle optimierte Tools und arbeitet innerhalb des LangGraph-Frameworks

4. **Reporter**: Der abschlie√üende Prozessor f√ºr Datenanalyseausgaben
   - Aggregation von Erkenntnissen des Datenanalyseteams
   - Verarbeitung und Organisation gesammelter Informationen
   - Erstellung umfassender Datenanalyseberichte

## Text-to-Speech-Integration

DataNova enth√§lt jetzt eine Text-to-Speech-(TTS)-Funktion, mit der Sie Forschungsberichte in Audio umwandeln k√∂nnen. Diese Funktion verwendet die Volcengine TTS API zur Erstellung hochwertiger Text-Audio. Eigenschaften wie Geschwindigkeit, Lautst√§rke und Tonh√∂he k√∂nnen ebenfalls angepasst werden.

### Verwendung der TTS-API

Sie k√∂nnen √ºber den `/api/tts`-Endpunkt auf die TTS-Funktion zugreifen:

```bash
# Beispiel-API-Aufruf mit curl
curl --location 'http://localhost:8000/api/tts' \
--header 'Content-Type: application/json' \
--data '{
    "text": "Dies ist ein Test der Text-to-Speech-Funktion.",
    "speed_ratio": 1.0,
    "volume_ratio": 1.0,
    "pitch_ratio": 1.0
}' \
--output speech.mp3
```

## Entwicklung

### Testen

Test-Suite ausf√ºhren:

```bash
# Alle Tests ausf√ºhren
make test

# Bestimmte Testdateien ausf√ºhren
pytest tests/integration/test_workflow.py

# Abdeckungstests ausf√ºhren
make coverage
```

### Codequalit√§t

```bash
# Code-Linting ausf√ºhren
make lint

# Code formatieren
make format
```

### Debuggen mit LangGraph Studio

DataNova verwendet LangGraph als Workflow-Architektur. Sie k√∂nnen LangGraph Studio verwenden, um Workflows in Echtzeit zu debuggen und zu visualisieren.

#### Lokales Ausf√ºhren von LangGraph Studio

DataNova enth√§lt eine `langgraph.json`-Konfigurationsdatei, die die Graphenstruktur und Abh√§ngigkeiten f√ºr LangGraph Studio definiert. Diese Datei verweist auf den im Projekt definierten Workflow-Graphen und l√§dt automatisch Umgebungsvariablen aus der `.env`-Datei.

##### Mac

```bash
# Installieren Sie den uv-Paketmanager, falls Sie ihn nicht haben
curl -LsSf https://astral.sh/uv/install.sh | sh

# Abh√§ngigkeiten installieren und den LangGraph-Server starten
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.12 langgraph dev --allow-blocking
```

##### Windows / Linux

```bash
# Abh√§ngigkeiten installieren
pip install -e .
pip install -U "langgraph-cli[inmem]"

# Den LangGraph-Server starten
langgraph dev
```

Nach dem Start des LangGraph-Servers sehen Sie mehrere URLs im Terminal:

- API: <http://127.0.0.1:2024>
- Studio UI: <https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024>
- API-Dokumentation: <http://127.0.0.1:2024/docs>

√ñffnen Sie den Studio UI-Link in Ihrem Browser, um auf die Debugging-Oberfl√§che zuzugreifen.

#### Verwendung von LangGraph Studio

In der Studio UI k√∂nnen Sie:

1. Den Workflow-Graphen visualisieren und sehen, wie Komponenten verbunden sind
2. Die Ausf√ºhrung in Echtzeit verfolgen, um zu verstehen, wie Daten durch das System flie√üen
3. Den Status jedes Schritts im Workflow pr√ºfen
4. Probleme debuggen, indem Sie die Ein- und Ausgabe jeder Komponente untersuchen
5. Feedback w√§hrend der Planungsphase geben, um den Forschungsplan zu verfeinern

Wenn Sie ein Datenanalyse-Thema in der Studio UI einreichen, k√∂nnen Sie den gesamten Workflow-Ausf√ºhrungsprozess sehen, einschlie√ülich:

- Die Planungsphase, in der der Datenanalyseplan erstellt wird
- Feedback-Schleifen, in denen der Plan ge√§ndert werden kann
- Datenanalysephasen f√ºr jeden Abschnitt
- Abschlie√üende Berichtsgenerierung

### Aktivierung von LangSmith-Tracing

DataNova unterst√ºtzt die LangSmith-Tracing-Funktionalit√§t, um Ihnen bei der Fehlersuche und √úberwachung von Workflows zu helfen. Um LangSmith-Tracing zu aktivieren:

1. Stellen Sie sicher, dass Sie die folgende Konfiguration in Ihrer `.env`-Datei haben (siehe `.env.example`):

   ```bash
   LANGSMITH_TRACING=true
   LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
   LANGSMITH_API_KEY="xxx"
   LANGSMITH_PROJECT="xxx"
   ```

2. Starten Sie LangSmith-Tracing lokal, indem Sie Folgendes ausf√ºhren:

   ```bash
   langgraph dev
   ```

Dadurch wird die Tracing-Visualisierung in LangGraph Studio aktiviert und Ihre Traces werden zur √úberwachung und Analyse an LangSmith gesendet.

## Docker

Sie k√∂nnen dieses Projekt auch mit Docker ausf√ºhren.

Zuerst m√ºssen Sie den Abschnitt [Konfiguration](#konfiguration) unten lesen. Stellen Sie sicher, dass die `.env`- und `.conf.yaml`-Dateien bereit sind.

Erstellen Sie als N√§chstes Ihr eigenes Webserver-Docker-Image:

```bash
docker build -t datanova-api .
```

Starten Sie abschlie√üend den Docker-Container, der den Webserver ausf√ºhrt:

```bash
# Ersetzen Sie datanova-api-app durch Ihren bevorzugten Containernamen
# Starten Sie den Server und binden Sie ihn an localhost:8000
docker run -d -t -p 127.0.0.1:8000:8000 --env-file .env --name datanova-api-app datanova-api

# Stoppen Sie den Server
docker stop datanova-api-app
```

### Docker Compose

Sie k√∂nnen dieses Projekt auch mit Docker Compose einrichten:

```bash
# Docker-Images erstellen
docker compose build

# Den Server starten
docker compose up
```

> [!WARNING]
> Wenn Sie DataNova in einer Produktionsumgebung bereitstellen m√∂chten, f√ºgen Sie bitte Authentifizierung zur Website hinzu und bewerten Sie die Sicherheitspr√ºfungen f√ºr MCPServer und Python Repl.

## Beispiele

Die folgenden Beispiele zeigen die F√§higkeiten von DataNova:

### Datenanalyseberichte

1. **E-Commerce-Datenlagerdesign** - Sternschema-Design f√ºr ein E-Commerce-Analyse-Datenlager
   - Diskussion √ºber Faktentabellen-, Dimensionstabellen-Design und bew√§hrte Datenmodellierungspraktiken
   - [Vollst√§ndigen Bericht anzeigen](examples/ecommerce_data_warehouse_design.md)

2. **SQL-Abfrageoptimierungsstrategien** - SQL-Abfrageleistungs-Optimierung f√ºr gro√üe Datens√§tze
   - Erkundung von Indizierungsstrategien, Abfrageneuschreibung und Kostenoptimierungstechniken
   - [Vollst√§ndigen Bericht anzeigen](examples/sql_query_optimization.md)

3. **Aufbau von Echtzeit-Datenpipelines** - Aufbau von Echtzeit-Datenpipelines mit modernen Streaming-Technologien
   - Forschung zu Kafka, Spark Streaming und Echtzeit-Datenverarbeitungsarchitekturen
   - [Vollst√§ndigen Bericht anzeigen](examples/realtime_data_pipeline.md)

4. **Datenqualit√§ts√ºberwachungsrahmen** - Implementierung automatisierter Datenqualit√§tspr√ºfungen und -√ºberwachung
   - Erkundung von Datenqualit√§tsmetriken, Anomalieerkennung und automatisierten Abhilfestrategien
   - [Vollst√§ndigen Bericht anzeigen](examples/data_quality_monitoring.md)

5. **Was ist LLM?** - Eine tiefgehende Erkundung gro√üer Sprachmodelle
   - Diskussion √ºber Architektur, Training, Anwendungen und ethische √úberlegungen
   - [Vollst√§ndigen Bericht anzeigen](examples/what_is_llm.md)

6. **Wie verwendet man Claude f√ºr Tiefgang-Forschung?** - Best Practices und Workflows f√ºr die Verwendung von Claude in Tiefgang-Forschung
   - Deckt Prompt-Engineering, Datenanalyse und Integration mit anderen Tools ab
   - [Vollst√§ndigen Bericht anzeigen](examples/how_to_use_claude_deep_research.md)

7. **KI-Einf√ºhrung im Gesundheitswesen: Einflussfaktoren** - Analyse der Faktoren, die die KI-Einf√ºhrung im Gesundheitswesen beeinflussen
   - Diskussion √ºber KI-Technologien, Datenqualit√§t, ethische √úberlegungen, Wirtschaftsbewertung, Organisationsbereitschaft und digitale Infrastruktur
   - [Vollst√§ndigen Bericht anzeigen](examples/AI_adoption_in_healthcare.md)

8. **Auswirkung von Quantencomputing auf Kryptographie** - Analyse der Auswirkung von Quantencomputing auf Kryptographie

   - Diskussion √ºber Schwachstellen klassischer Kryptographie, Post-Quanten-Kryptographie und quantenresistente kryptographische L√∂sungen
   - [Vollst√§ndigen Bericht anzeigen](examples/Quantum_Computing_Impact_on_Cryptography.md)

9. **Cristiano Ronaldos Leistungshighlights** - Analyse der Leistungshighlights von Cristiano Ronaldo
   - Diskussion √ºber seine Karriereerfolge, internationale Tore und Leistungen in verschiedenen Wettbewerben
   - [Vollst√§ndigen Bericht anzeigen](examples/Cristiano_Ronaldo's_Performance_Highlights.md)

Um diese Beispiele auszuf√ºhren oder Ihre eigenen Forschungsberichte zu erstellen, k√∂nnen Sie die folgenden Befehle verwenden:

```bash
# Mit einer bestimmten Abfrage ausf√ºhren
uv run main.py "Entwerfen Sie eine Datenlagerarchitektur f√ºr E-Commerce-Analysen"

# Mit benutzerdefinierten Planungsparametern ausf√ºhren
uv run main.py --max_plan_iterations 3 "Wie optimiert man die Leistung komplexer SQL-Abfragen?"

# Im interaktiven Modus mit integrierten Fragen ausf√ºhren
uv run main.py --interactive

# Oder mit grundlegendem interaktivem Prompt ausf√ºhren
uv run main.py

# Alle verf√ºgbaren Optionen anzeigen
uv run main.py --help
```

### Interaktiver Modus

DataNova unterst√ºtzt einen interaktiven Modus mit integrierten Fragen in Englisch und Chinesisch, die speziell auf Szenarien der Datenlagerentwicklung zugeschnitten sind:

1. Interaktiven Modus starten:

   ```bash
   uv run main.py --interactive
   ```

2. Bevorzugte Sprache ausw√§hlen (Englisch oder Chinesisch)

3. Aus der integrierten Datenlager-Fragenliste w√§hlen oder die Option ausw√§hlen, eine eigene Frage zu stellen

4. Das System verarbeitet Ihre Frage und erstellt einen umfassenden Datenanalysebericht

### Human-in-the-Loop

DataNova enth√§lt einen Human-in-the-Loop-Mechanismus, der es Ihnen erm√∂glicht, Datenanalysepl√§ne vor der Ausf√ºhrung zu √ºberpr√ºfen, zu bearbeiten und zu genehmigen:

1. **Plan√ºberpr√ºfung**: Wenn Human-in-the-Loop aktiviert ist, zeigt das System Ihnen den generierten Datenanalyseplan vor der Ausf√ºhrung an

2. **Feedback geben**: Sie k√∂nnen:

   - Den Plan akzeptieren, indem Sie `[ACCEPTED]` antworten
   - Den Plan bearbeiten, indem Sie Feedback geben (z.B. `[EDIT PLAN] F√ºgen Sie weitere Schritte zu Datenqualit√§tspr√ºfungen hinzu`)
   - Das System wird Ihr Feedback einbeziehen und einen √ºberarbeiteten Plan erstellen

3. **Automatische Annahme**: Sie k√∂nnen die automatische Annahme aktivieren, um den √úberpr√ºfungsprozess zu √ºberspringen:
   - √úber API: Setzen Sie `auto_accepted_plan: true` in der Anfrage

4. **API-Integration**: Bei Verwendung der API k√∂nnen Sie Feedback √ºber den `feedback`-Parameter geben:

   ```json
   {
     "messages": [{ "role": "user", "content": "Entwerfen Sie eine E-Commerce-Datenlagerarchitektur" }],
     "thread_id": "my_thread_id",
     "auto_accepted_plan": false,
     "feedback": "[EDIT PLAN] F√ºgen Sie mehr Inhalte zur Echtzeit-Datenverarbeitung hinzu"
   }
   ```

### Befehlszeilenargumente

DataNova unterst√ºtzt mehrere Befehlszeilenargumente zur Anpassung des Verhaltens:

- **query**: Die zu verarbeitende Datenanalyseabfrage (kann mehrere W√∂rter sein)
- **--interactive**: Im interaktiven Modus mit integrierten Fragen ausf√ºhren
- **--max_plan_iterations**: Maximale Anzahl von Planungszyklen (Standard: 1)
- **--max_step_num**: Maximale Anzahl von Schritten in einem Datenanalyseplan (Standard: 3)
- **--debug**: Ausf√ºhrliche Debug-Protokollierung aktivieren

## FAQ

Siehe [FAQ.md](docs/FAQ.md) f√ºr weitere Details.

## Lizenz

Dieses Projekt ist Open Source unter der [MIT-Lizenz](./LICENSE).

## Danksagungen

DataNova basiert auf der hervorragenden Arbeit der Open-Source-Community. Wir sch√§tzen alle Projekte und Mitwirkenden zutiefst, die DataNova m√∂glich gemacht haben. Tats√§chlich stehen wir auf den Schultern von Riesen.

Wir m√∂chten den folgenden Projekten f√ºr ihre wertvollen Beitr√§ge herzlich danken:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Ihr hervorragendes Framework treibt unsere LLM-Interaktionen und -Ketten an und erm√∂glicht eine nahtlose Integration und Funktionalit√§t.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Ihr innovativer Ansatz f√ºr Multi-Agenten-Orchestrierung ist entscheidend f√ºr die Implementierung komplexer Workflows von DataNova.

Diese Projekte demonstrieren die transformative Kraft der Open-Source-Zusammenarbeit, und wir sind stolz darauf, auf ihren Grundlagen aufzubauen.

### Hauptmitwirkende

Wir danken den Hauptautoren von `DataNova` herzlich f√ºr ihre Vision, Leidenschaft und Hingabe, die dieses Projekt m√∂glich gemacht haben:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Ihr unersch√ºtterliches Engagement und Ihre Expertise sind die treibende Kraft hinter dem Erfolg von DataNova. Wir sind geehrt, dass Sie diese Reise leiten.

## Sternverlauf

[![Star History Chart](https://api.star-history.com/svg?repos=hszhsz/DataNova&type=Date)](https://star-history.com/#hszhsz/DataNova&Date)